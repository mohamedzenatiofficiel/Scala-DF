[debug] > Exec(run, None, None)
[debug] Evaluating tasks: Compile / run
[debug] Running task... Cancel: Signal, check cycles: false, forcegc: true
[info] compiling 1 Scala source to C:\Users\zmoha\OneDrive\Documents\spark-df\target\scala-2.13\classes ...
[error] C:\Users\zmoha\OneDrive\Documents\spark-df\src\main\scala\fr\data\spark\DataFrame.scala:17:18: not found: type SparkContext
[error]     val sc = new SparkContext(conf)
[error]                  ^
[error] C:\Users\zmoha\OneDrive\Documents\spark-df\src\main\scala\fr\data\spark\DataFrame.scala:17:31: not found: value conf
[error]     val sc = new SparkContext(conf)
[error]                               ^
[error] two errors found
[error] (Compile / compileIncremental) Compilation failed
[error] Total time: 5 s, completed 11 mars 2022 Ã  15:24:50
[debug] > Exec(idea-shell, None, None)
